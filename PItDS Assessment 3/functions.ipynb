{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import geopandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DEBUG = False\n",
    "STATIONS_DATA_URL = \"https://www.metoffice.gov.uk/pub/data/weather/uk/climate/stationdata/\"\n",
    "STATIONS_DATA_DIR = \"./data/part1/\"\n",
    "\n",
    "WELLBEING_DATA_URL = \"https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fwellbeing%2fdatasets%2fpersonalwellbeingestimatesgeographicalbreakdown%2f201415/geographicbreakdownreferencetable_tcm77-417203.xls\"\n",
    "WELLBEING_DATA_FILENAME = \"geographicbreakdownreferencetable_tcm77-417203.xls\"\n",
    "WELLBEING_DATA_DIR = \"./data/part3/\"\n",
    "\n",
    "N_CLUSTERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(s):\n",
    "    global DEBUG\n",
    "    if DEBUG:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanNumericValues(f, type_cast=float):\n",
    "    number = re.search(string=f, pattern=\"(\\-?(\\d*\\.)?\\d+)\")\n",
    "    if number is None:\n",
    "        return None\n",
    "    else:\n",
    "        return type_cast(number.group(1))\n",
    "\n",
    "def cleanNumericValuesInt(f):\n",
    "    return cleanNumericValues(f, type_cast=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadDataFiles(station_filename, stations_data_dir = STATIONS_DATA_DIR, stations_data_url = STATIONS_DATA_URL):\n",
    "    \n",
    "    stations_data_files = os.listdir(stations_data_dir)\n",
    "    \n",
    "    if station_filename in stations_data_files:\n",
    "        echo(f\"File {stations_data_dir}{station_filename} already exists\")\n",
    "    else:\n",
    "        echo(f\"Download URL: {stations_data_url}{station_filename}\")\n",
    "        echo(f\"Download Dir: {stations_data_dir}{station_filename}\")\n",
    "        echo(f\"Downloading {station_filename}...\")\n",
    "        \n",
    "        http_request = requests.get(f\"{stations_data_url}{station_filename}\")\n",
    "\n",
    "        with open(f\"{stations_data_dir}{station_filename}\", 'wb') as f:\n",
    "            f.write(http_request.content)\n",
    "\n",
    "        # Retrieve HTTP meta-data\n",
    "        echo(f\"Status code: {http_request.status_code}\")\n",
    "        echo(f\"File content type: {http_request.headers['content-type']}\")\n",
    "        \n",
    "        echo(f\"Finished downloading {station_filename}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadWellbeingDataset():\n",
    "    # Open the dataset directory\n",
    "    data_files = os.listdir(WELLBEING_DATA_DIR)\n",
    "    \n",
    "    # If dataset exists skip\n",
    "    if WELLBEING_DATA_FILENAME in data_files:\n",
    "        echo(f\"File {WELLBEING_DATA_DIR}{WELLBEING_DATA_FILENAME} already exists\")\n",
    "    \n",
    "    # If dataset doesn't exist, download it\n",
    "    else:\n",
    "        echo(f\"Download URL: {WELLBEING_DATA_URL}\")\n",
    "        echo(f\"Download Dir: {WELLBEING_DATA_DIR}{WELLBEING_DATA_FILENAME}\")\n",
    "        echo(f\"Downloading {WELLBEING_DATA_FILENAME}...\")\n",
    "        \n",
    "        http_request = requests.get(f\"{WELLBEING_DATA_URL}\")\n",
    "\n",
    "        with open(f\"{WELLBEING_DATA_DIR}{WELLBEING_DATA_FILENAME}\", 'wb') as f:\n",
    "            f.write(http_request.content)\n",
    "\n",
    "        # Retrieve HTTP meta-data\n",
    "        echo(f\"Status code: {http_request.status_code}\")\n",
    "        echo(f\"File content type: {http_request.headers['content-type']}\")\n",
    "        \n",
    "        echo(f\"Finished downloading {WELLBEING_DATA_FILENAME}...\")\n",
    "    \n",
    "    return f\"{WELLBEING_DATA_DIR}{WELLBEING_DATA_FILENAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberOfLinesToSkip(file_path, stop_string):\n",
    "    # file_path:\n",
    "    # stop_string: The line on which this string is found is the first line to start reading. \n",
    "    # All the lines before are to be skipped.\n",
    "    \n",
    "    lines_to_skip = 0\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        \n",
    "        while(1):\n",
    "            line = f.readline()\n",
    "            \n",
    "            # Check if we reached the end of the file\n",
    "            if line == '':\n",
    "                break\n",
    "                \n",
    "            # for every line in which the string stop_string is not found increment\n",
    "            # the variable lines_to_skip by one to skip these lines later when reading\n",
    "            # the file into a Pandas DataFrame\n",
    "            if stop_string not in line:\n",
    "                lines_to_skip = lines_to_skip + 1\n",
    "            else:\n",
    "                break;\n",
    "                \n",
    "    return lines_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationData(file_path):\n",
    "    # file_path:\n",
    "    \n",
    "    location_name = \"\"\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        \n",
    "        search_next_line = False\n",
    "        \n",
    "        location_data = {\"area\": None, \"dms_e\": None, \"dms_n\": None, \"lat\": None, \"lon\": None, \"elevation\": None}\n",
    "        location_data[\"area\"] = f.readline().strip()\n",
    "        \n",
    "        for i in range(0,5):\n",
    "            \n",
    "            line = f.readline()\n",
    "            \n",
    "            # Check if we reached the end of the file\n",
    "            if line == '':\n",
    "                break\n",
    "            \n",
    "            if str(line).lower().find(\"location\") != -1 or search_next_line:\n",
    "                \n",
    "                search_next_line = False\n",
    "                \n",
    "                # Location 433900E 387200N, Lat 53.381 Lon -1.490, 131 metres amsl\n",
    "                loc = re.search(string=line, pattern=\"(\\d+E) *(\\d+N)\")\n",
    "                if loc is not None:\n",
    "                    location_data[\"dms_e\"] = (loc.group(1))\n",
    "                    location_data[\"dms_n\"] = (loc.group(2))\n",
    "                else: \n",
    "                    search_next_line = True\n",
    "                \n",
    "                loc = re.search(string=line, pattern=\"Lat *(\\-?\\d+(\\.\\d+)?) Lon *(\\-?\\d+(\\.\\d+)?)\")\n",
    "                if loc is not None:\n",
    "                    location_data[\"lat\"] = (loc.group(1))\n",
    "                    location_data[\"lon\"] = (loc.group(3))\n",
    "                else: \n",
    "                    search_next_line = True\n",
    "                    \n",
    "                loc = re.search(string=line, pattern=\"(\\d+) *(m|metres)\")\n",
    "                if loc is not None:\n",
    "                    location_data[\"elevation\"] = (loc.group(1))\n",
    "                else: \n",
    "                    search_next_line = True\n",
    "                \n",
    "    return location_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function take a Pandas DataFrame as input and plots a map with the weather stations\n",
    "# colored according to their cluster.\n",
    "def plotMap(X, X2=None, hide_legend=False, cluster_labels:dict=None):\n",
    "    \n",
    "    # Remove the default grid of Seaborn\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    # Group observations by station and count the how many times this station's readings were categorised \n",
    "    # under each cluster. Finally choose the cluster that received the highest number of observations for\n",
    "    # the station\n",
    "    clustered_stations = X.groupby(by=[\"station\", \"cluster\"], as_index=False).size().reset_index(name=\"count\")\n",
    "    clustered_stations = clustered_stations.groupby(by=[\"station\"], as_index=False)[\"count\"].max().merge(clustered_stations, on=[\"station\", \"count\"], how=\"inner\")\n",
    "    clustered_stations = clustered_stations.sort_values(by=\"cluster\")\n",
    "    \n",
    "    # Prepare the plot's canvas\n",
    "    fig, ax1, ax2 = None, None, None\n",
    "    if X2 is not None:\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(15, 10))\n",
    "        ax1.set_prop_cycle(color=get_cmap(\"tab10\").colors)\n",
    "        ax2.set_prop_cycle(color=get_cmap(\"tab10\").colors)\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(ncols=1, figsize=(8, 10))\n",
    "        ax1.set_prop_cycle(color=get_cmap(\"tab10\").colors)\n",
    "    \n",
    "    # Choose the map style\n",
    "    world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "    \n",
    "    # We restrict to UK\n",
    "    world[world.name == \"United Kingdom\"].plot(color='white', edgecolor='black', figsize=(10,10), ax=ax1)\n",
    "\n",
    "    global station_locations\n",
    "\n",
    "    # Plot the Map\n",
    "    for i, cluster in enumerate(clustered_stations.cluster.unique()):\n",
    "        tmp_df = station_locations.merge(clustered_stations[clustered_stations.cluster == cluster], on=[\"station\"], how=\"inner\")\n",
    "        gdf = geopandas.GeoDataFrame(tmp_df, geometry=geopandas.points_from_xy(tmp_df.lon, tmp_df.lat))\n",
    "        \n",
    "        # Set the cluster label\n",
    "        label = f\"Cluster {cluster}\"\n",
    "        if cluster_labels is not None:\n",
    "            label = f\"{cluster_labels[cluster]}\"\n",
    "        gdf.plot(ax=ax1, label=label)\n",
    "        \n",
    "        # Show station names on the map\n",
    "        for x, y, label in zip(gdf.geometry.x, gdf.geometry.y, gdf.station):\n",
    "            ax1.annotate(label.capitalize(), xy=(x, y), xytext=(3, 3), textcoords=\"offset points\", fontsize=\"x-small\")\n",
    "\n",
    "    if not hide_legend:\n",
    "        ax1.legend()\n",
    "    \n",
    "    if X2 is not None:\n",
    "        clustered_stations = X2.groupby(by=[\"station\", \"cluster\"], as_index=False).size().reset_index(name=\"count\")\n",
    "        clustered_stations = clustered_stations.groupby(by=[\"station\"], as_index=False)[\"count\"].max().merge(clustered_stations, on=[\"station\", \"count\"], how=\"inner\")\n",
    "        clustered_stations = clustered_stations.sort_values(by=\"cluster\")\n",
    "        \n",
    "        # We restrict to Europe\n",
    "        world[world.name == \"United Kingdom\"].plot(color='white', edgecolor='black', figsize=(10,10), ax=ax2)\n",
    "\n",
    "        # We can now plot our ``GeoDataFrame``.\n",
    "        for i, cluster in enumerate(clustered_stations.cluster.unique()):\n",
    "            tmp_df = station_locations.merge(clustered_stations[clustered_stations.cluster == cluster], on=[\"station\"], how=\"inner\")\n",
    "            gdf = geopandas.GeoDataFrame(tmp_df, geometry=geopandas.points_from_xy(tmp_df.lon, tmp_df.lat))\n",
    "#             gdf.plot(ax=ax2, label=f\"Cluster {cluster}\")\n",
    "            \n",
    "            # Set the cluster label\n",
    "            label = f\"Cluster {cluster}\"\n",
    "            if cluster_labels is not None:\n",
    "                label = f\"{cluster_labels[cluster]}\"\n",
    "            gdf.plot(ax=ax2, label=label)\n",
    "        \n",
    "            # Show station names on the map\n",
    "            for x, y, label in zip(gdf.geometry.x, gdf.geometry.y, gdf.station):\n",
    "                ax2.annotate(label.capitalize(), xy=(x, y), xytext=(3, 3), textcoords=\"offset points\", fontsize=\"x-small\")\n",
    "        \n",
    "        # Show the legend (List of clusters)\n",
    "        if not hide_legend:\n",
    "            ax2.legend()\n",
    "            \n",
    "    return fig, ax1, ax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function take a Pandas DataFrame as input and plots a map with the weather stations\n",
    "# colored according to their cluster.\n",
    "def plotSingleMap(X, ax, hide_legend=False, show_station_names=False, cluster_labels=None):\n",
    "    \n",
    "    # Remove the default grid of Seaborn\n",
    "    sns.set_style(\"white\")\n",
    "    \n",
    "    # Group observations by station and count the how many times this station's readings were categorised \n",
    "    # under each cluster. Finally choose the cluster that received the highest number of observations for\n",
    "    # the station\n",
    "    clustered_stations = X.groupby(by=[\"station\", \"cluster\"], as_index=False).size().reset_index(name=\"count\")\n",
    "    clustered_stations = clustered_stations.groupby(by=[\"station\"], as_index=False)[\"count\"].max().merge(clustered_stations, on=[\"station\", \"count\"], how=\"inner\")\n",
    "    clustered_stations = clustered_stations.sort_values(by=\"cluster\")\n",
    "    \n",
    "    # Prepare the plot's canvas\n",
    "    ax.set_prop_cycle(color=get_cmap(\"tab20\").colors)\n",
    "    \n",
    "    # Choose the map style\n",
    "    world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "    \n",
    "    # We restrict to UK\n",
    "    world[world.name == \"United Kingdom\"].plot(color='white', edgecolor='black', ax=ax)\n",
    "\n",
    "    # Plot the Map\n",
    "    for i, cluster in enumerate(clustered_stations.cluster.unique()):\n",
    "        tmp_df = station_locations.merge(clustered_stations[clustered_stations.cluster == cluster], on=[\"station\"], how=\"inner\")\n",
    "        gdf = geopandas.GeoDataFrame(tmp_df, geometry=geopandas.points_from_xy(tmp_df.lon, tmp_df.lat))\n",
    "        \n",
    "        # Set the cluster label\n",
    "        label = f\"Cluster {cluster}\"\n",
    "        if cluster_labels is not None:\n",
    "            label = f\"{cluster_labels[cluster]}\"\n",
    "        gdf.plot(ax=ax, label=label)\n",
    "        \n",
    "        # Show station names on the map\n",
    "        if show_station_names:\n",
    "            for x, y, label in zip(gdf.geometry.x, gdf.geometry.y, gdf.station):\n",
    "                ax.annotate(label.capitalize(), xy=(x, y), xytext=(3, 3), textcoords=\"offset points\", fontsize=\"x-small\")\n",
    "        \n",
    "    if not hide_legend:\n",
    "        ax.legend()\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}